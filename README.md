# LLM-Multi-lingual-
Multilingual RAG with Mistral-7B-Instruct-v0.2 &amp; LangChain. This Google Colab notebook demonstrates a powerful Retrieval-Augmented Generation (RAG) pipeline for question answering on custom PDF documents. It uses 4-bit quantization (bitsandbytes) to run the Mistral 7B LLM and a Multilingual embedding model (BAAI/bge-m3) with FAISS 
